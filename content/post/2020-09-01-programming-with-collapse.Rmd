---
title: "Efficient Grouped Programming in R and/or C/C++ - with the collapse Package"
author: "Sebastian Krantz"
date: '2020-09-01'
slug: programming-with-collapse
categories: ["R"]
tags: ["R", "collapse", "grouped", "weighted", "statistical", "programming"]
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, fig.width = 8, fig.height = 5, out.width = '100%', cache = TRUE)

oldopts <- options(width = 101L)
```

[*collapse*](https://sebkrantz.github.io/collapse/) is a C/C++ based package for data transformation and statistical computing in R. Among other features it introduces an excellent and highly efficient architecture for grouped (and weighted) statistical programming in R. This post briefly explains this architecture and demonstrates:

1. How to program highly efficient grouped statistical computations and data manipulations in R using the grouped functions supplied by *collapse*.

2. How to use the grouping mechanism of *collapse* with custom C/C++ code to create further efficient grouped functions/operations in R.

# Essentials: *collapse* Grouping Objects
*collapse* uses grouping objects as essential inputs for grouped computations. These objects are created from vectors or lists of vectors (i.e. data frames) using the function `GRP()`:

```{r, message=FALSE, warning=FALSE}
library(collapse)
# A dataset supplied with collapse providing sectoral value added (VA) and employment (EMP)
head(GGDC10S, 3)
fdim(GGDC10S)

# Creating a grouping object (by default return.order = FALSE as the ordering is typically not needed)
g <- GRP(GGDC10S, c("Country", "Variable"), return.order = TRUE)
# Printing it
print(g)
# Plotting it
plot(g)
```
Grouping is done very efficiently using radix-based ordering in C (thanks to *data.table* source code). The structure of this object is shown below:
```{r}
str(g)
```
The first three slots of this object provide the number of unique groups, a group-id matching each value/row to a group^[By default (`sort = TRUE`) the grouping is ordered, which is equivalent to *data.table* grouping with `keyby`.], and a vector of group-sizes. The fourth slot provides the unique groups (default `return.groups = TRUE`), followed by the names of the grouping variables, a logical vector showing whether the grouping is ordered (default `sort = TRUE`), and the ordering vector which can be used to sort the data alphabetically according to the grouping variables (default `return.order = FALSE`). 

# Grouped Programming in R
*collapse* provides a whole ensemble of C++ based generic statistical functions that can use these 'GRP' objects to internally perform (column-wise) grouped (and weighted) computations on vectors, matrices and data frames in R. Their names are contained in the global macro `.FAST_FUN`:

```{r}
.FAST_FUN
```
Additional functions supporting grouping objects are `TRA` (grouped replacing and sweeping out statistics), `BY` (split-apply-combine computing) and `collap` (advanced data aggregation with multiple functions). 

To provide a brief example, we can compute a grouped mean of the above data using:
```{r}
head(fmean(GGDC10S[6:16], g))
```
By default (`use.g.names = TRUE`), group names are added as names (vectors) or row-names (matrices and data frames) to the result. For data frames we can also add the grouping columns again using^[`add_vars` is a faster alternative to `cbind` and `get_vars` is a faster alternative to `[.data.frame` for subsetting columns.]: 
```{r}
head(add_vars(g[["groups"]], fmean(get_vars(GGDC10S, 6:16), g, use.g.names = FALSE)))
```
The execution cost of all of these functions is extremely small, so the performance is essentially limited by C++, not by R. 
```{r}
library(microbenchmark)
microbenchmark(call = add_vars(g[["groups"]], fmean(get_vars(GGDC10S, 6:16), g, use.g.names = FALSE)))
```

We can use these functions to write very efficient grouped code in R. This shows a simple application in panel data econometrics comparing a pooled OLS to a group means, a between and a within estimator computed on the demeaned data^[A random effects estimator could easily be added, see the example [here](https://sebkrantz.github.io/collapse/reference/fbetween_fwithin.html).]:

```{r}
Panel_Ests <- function(formula, data, pids) {
  # Get variables as character string, first variable is dependent variable
  vars <- all.vars(formula)
  # na_omit and qM are faster replacements for na.omit and as.matrix
  data_cc <- na_omit(qM(get_vars(data, vars)), na.attr = TRUE)
  cc <- attr(data_cc, "na.action")
  # We don't need the unique groups or the call. ss() is faster replacement for [.data.frame 
  g <- GRP(ss(data, -cc, pids), return.groups = FALSE, call = FALSE)
  # Computing group means
  mean_data_cc <- fmean(data_cc, g, use.g.names = FALSE)
  # This computes regression coefficients
  reg <- function(x) qr.coef(qr(cbind(Intercept = 1, x[, -1L, drop = FALSE])), x[, 1L])
  
  qM(list(Pooled = reg(data_cc),
          Means = reg(mean_data_cc),
          # This replaces data values with the group-mean -> between-group estimator
          Between = reg(TRA(data_cc, mean_data_cc, "replace_fill", g)),
          # This subtracts the group-means -> within-group estimator
          Within = reg(TRA(data_cc, mean_data_cc, "-", g))))
}

# Value Added data
round(Panel_Ests(SUM ~ AGR + MIN + MAN, fsubset(GGDC10S, Variable == "VA"), "Country"), 4)

# Employment data
round(Panel_Ests(SUM ~ AGR + MIN + MAN, fsubset(GGDC10S, Variable == "EMP"), "Country"), 4)
```
It would be easy to add an option for sampling weights as `fmean` also supports weighted grouped computations. A benchmark below shows that this series of estimators is executed very efficiently and scales nicely to large data (quite a bit faster than using `plm` to do it). 
```{r}
# Benchmark on VA data  
VA_data <- fsubset(GGDC10S, Variable == "VA")
microbenchmark(call = Panel_Ests(SUM ~ AGR + MIN + MAN, VA_data, "Country"))
```

There are lots and lots of other applications that can be devised in R using the `.FAST_FUN` and efficient programming with grouping objects.

## Creating Grouped Functions in C/C++

It is also possible to just use 'GRP' objects as input to new grouped functions written in C or C++. Below I use *Rcpp* to create a generic grouped `anyNA` function for vectors: 

```{Rcpp, eval = FALSE}
// [[Rcpp::plugins(cpp11)]]
#include <Rcpp.h>
using namespace Rcpp;

// Inputs: 
// x - A vector of any type 
// ng - The number of groups - supplied by GRP() in R
// g - An integer grouping vector - supplied by GRP() in R

// Output: A plain logical vector of size ng

template <int RTYPE>
LogicalVector ganyNACppImpl(Vector<RTYPE> x, int ng, IntegerVector g) {
  int l = x.size();
  if(l != g.size()) stop("length(x) must match length(g)");
  LogicalVector out(ng);

  if(RTYPE == REALSXP) { // numeric vector: all logical operations on NA/NaN evaluate to false, except != which is true.
    for(int i = 0; i < l; ++i) if(x[i] != x[i]) out[g[i]-1] = true;
  } else { // other vectors
    for(int i = 0; i < l; ++i) if(x[i] == Vector<RTYPE>::get_na()) out[g[i]-1] = true;
  }

  return out;
}

// disabling other data types (lists, complex values etc.)
template <>
LogicalVector ganyNACppImpl(Vector<CPLXSXP> x, int ng, IntegerVector) {
  stop("Not supported SEXP type!");
}

template <>
LogicalVector ganyNACppImpl(Vector<VECSXP> x, int ng, IntegerVector) {
  stop("Not supported SEXP type!");
}

template <>
LogicalVector ganyNACppImpl(Vector<RAWSXP> x, int ng, IntegerVector) {
  stop("Not supported SEXP type!");
}

template <>
LogicalVector ganyNACppImpl(Vector<EXPRSXP> x, int ng, IntegerVector) {
  stop("Not supported SEXP type!");
}

// [[Rcpp::export]]
LogicalVector ganyNACpp(const SEXP& x, int ng = 0, const IntegerVector& g = 0){
  RCPP_RETURN_VECTOR(ganyNACppImpl, x, ng, g);
}

```
On the R side things are then pretty simple: 
```{r, message=FALSE, cache=TRUE}
library(Rcpp)   
sourceCpp("ganyNA.cpp")

ganyNA <- function(x, g, use.g.names = TRUE) {
  # Option group.sizes = FALSE prevents tabulation of levels if a factor is passed
  g <- GRP(g, return.groups = use.g.names, group.sizes = FALSE, call = FALSE)
  res <- ganyNACpp(x, g[[1L]], g[[2L]])
  # GRPnames creates unique group names. For vectors they need not be character typed.
  if(use.g.names) return(setNames(res, GRPnames(g, force.char = FALSE)))
  res
}
```
Strictly speaking there are different options to set this up: `GRP()` is a S3 generic function with a default method applying to atomic vectors and lists / data frames, but also a 'factor' method converting factors to 'GRP' objects. Above I have used the generic `GRP` function with the option `group.sizes = FALSE`, so factors are efficiently converted without tabulating the levels. This provides more efficiency if a factor is passed to `g`, but will not drop unused factor levels. The alternative is to use `g <- GRP.default(g, return.groups = use.g.names, call = FALSE)`, which will get rid of unused factor levels, but using factors for grouping is just as efficient as any other vector. 

```{r}
head(ganyNA(GGDC10S$SUM, fselect(GGDC10S, Country, Variable)))

# 10 million obs and 1 million groups, 1% of data missing 
x <- na_insert(rnorm(1e7), prop = 0.01)
g <- sample.int(1e6, 1e7, TRUE)
system.time(ganyNA(x, g))
system.time(ganyNA(x, g, use.g.names = FALSE))

# Using a factor grouping variable: More efficient but does not drop any unused levels
f <- qF(g, na.exclude = FALSE) # Efficiently creating a factor (qF is faster as.factor)
system.time(ganyNA(x, f))
system.time(ganyNA(x, f, use.g.names = FALSE))

```

We could additionally add a `TRA` argument and then internally call the `TRA()` function to allow for replacing and sweeping out statistics, but this does not make much sense here. 

```{r, echo=FALSE}
options(oldopts)
```

